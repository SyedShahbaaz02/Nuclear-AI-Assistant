{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3ce63b",
   "metadata": {},
   "source": [
    "## LER Classifier Notebook\n",
    "\n",
    "This notebook extracts LERs, downloaded from ADAMs, fetch relevant IRs and creates a classifier to identify IRs that are promoted to LER vs others. This will then find, based on probability, IRs that are borderline cases. \n",
    "\n",
    "Note: This notebook must be run outside dev container to run successfully. Pyodbc throws error when run inside container.\n",
    "\n",
    "To run outside, you need this notebook and dependent libraries (alcs_global.py, alcs_llm.py) and fix relative path below\n",
    "to reference them correctly.\n",
    "\n",
    "### Narrative\n",
    "While creating this final version of the code, various experiments were done to reach at final set of features. \n",
    "File \"./log/experiment_log.txt\" captures those experiment results with various features. Please read the file for the details.\n",
    "\n",
    "Also, this code generates pred_full.csv file that contains the probability of full dataset and various IRs to be LERs. Below code find the best threshold for separating positive and negative classes. Though LERs set is statis, as it comes from NRC, Non-LERs will change\n",
    "with every run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variable keys\n",
    "env_var_openai_key = 'NUREG_AZURE_OPENAI_SERVICE_KEY'\n",
    "env_var_openai_uri = 'NUREG_AZURE_OPENAI_SERVICE_URI'\n",
    "env_var_openai_model = 'NUREG_AZURE_OPENAI_CHATGPT_MODEL'\n",
    "env_var_openai_embedding_model = 'SEARCH_EVAL_OPENAI_EMBEDDING_MODEL'\n",
    "env_var_storage_container_name = \"AZURE_STORAGE_CONTAINER_NAME\"\n",
    "env_var_storage_connection_string = \"AZURE_STORAGE_CONNECTION_STRING\"\n",
    "\n",
    "# Add custom library path\n",
    "import sys\n",
    "sys.path.append('../../src/evaluation/search/helper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pyodbc, os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote\n",
    "from alcs_llm import AzureOpenAIModel, AzureOpenAIService\n",
    "from alcs_global import Common\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142c1c3",
   "metadata": {},
   "source": [
    "### Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set paramters for Azure OpenAI\n",
    "azure_openai_model = AzureOpenAIModel(\n",
    "    open_api_key = os.getenv(env_var_openai_key),\n",
    "    open_api_uri = os.getenv(env_var_openai_uri),\n",
    "    chatgpt_model_id = os.getenv(env_var_openai_model)\n",
    ")\n",
    "\n",
    "# Initialize Azure OpenAI\n",
    "azure_openai = AzureOpenAIService(azure_openai_model = azure_openai_model)\n",
    "\n",
    "# Set embedding model from env\n",
    "embedding_model=os.getenv(env_var_openai_embedding_model)\n",
    "\n",
    "container_name = os.getenv(env_var_storage_container_name)\n",
    "connection_string = os.getenv(env_var_storage_connection_string)\n",
    "local_download_path = \"output/lers\"\n",
    "blob_folder_name = \"processed\"\n",
    "blob_file_filter = \".txt\"\n",
    "ler_output_csv = \"output/lers/ler_catalog.csv\"\n",
    "ler_ir_map_csv = \"log/ler_ir_map.csv\"\n",
    "test_pred_csv = \"log/pred_test.csv\"\n",
    "full_pred_csv = \"log/pred_full.csv\"\n",
    "\n",
    "# Initialize the BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7e728",
   "metadata": {},
   "source": [
    "### Download LERs summary text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996dafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the local directory exists\n",
    "if os.path.exists(local_download_path):\n",
    "    shutil.rmtree(local_download_path)\n",
    "os.makedirs(local_download_path, exist_ok=True)\n",
    "\n",
    "# List and download all blobs in the container\n",
    "print(\"Downloading blobs...\")\n",
    "blob_urls = []\n",
    "for blob in container_client.list_blobs(name_starts_with=blob_folder_name): \n",
    "\n",
    "    if blob.name.endswith(blob_file_filter):\n",
    "        blob_name = blob.name\n",
    "        local_file_path = os.path.join(local_download_path, blob_name)\n",
    "\n",
    "        blob_url = f\"{container_client.url}/{blob.name}\"\n",
    "        blob_urls.append(blob_url)\n",
    "\n",
    "        # Create directories for nested blobs\n",
    "        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "\n",
    "        # Download the blob\n",
    "        with open(local_file_path, \"wb\") as file:\n",
    "            blob_client = container_client.get_blob_client(blob_name)\n",
    "            file.write(blob_client.download_blob().readall())\n",
    "        # print(f\"Downloaded: {blob_name}\")\n",
    "\n",
    "print(f\"{len(blob_urls)} blobs downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67631ae7",
   "metadata": {},
   "source": [
    "### Consolidate LER meta info into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "data_dir = Path(f\"{local_download_path}/{blob_folder_name}\")\n",
    "for file in data_dir.glob(\"*.txt\"):\n",
    "    with open(file, \"r\") as f:\n",
    "        try:\n",
    "            records = json.load(f)\n",
    "            rows.append({\n",
    "                \"EVENTDATE\": records.get(\"event_date\", \"\"),\n",
    "                \"REPORTDATE\": records.get(\"report_date\", \"\"),\n",
    "                \"LERNUMBER\": records.get(\"ler_number\", \"\"),\n",
    "                \"FACILITYNAME\": records.get(\"facility_name\", \"\"),\n",
    "                \"TITLE\": records.get(\"title\", \"\"),\n",
    "                # \"content\": f\"Abstract:\\n{records.get('abstract', '')}\\n\\n{records.get('narrative', '')}\",\n",
    "                \"SUBSECTIONS\": \", \".join([f\"10 CFR {subsection}\" for subsection in records.get(\"cfr_requirements\",[])]),\n",
    "                \"FILENAME\": os.path.basename(f.name)\n",
    "                })\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"❌ Failed to parse {file}\")\n",
    "\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(ler_output_csv, index=False)\n",
    "    print(f\"✅ Generated ground truth CSV with {len(rows)} entries at {ler_output_csv}\")\n",
    "else:\n",
    "    print(\"⚠️ No valid LERs found to include in ground truth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f818b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read LER CSV\n",
    "df = pd.read_csv(ler_output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e396220",
   "metadata": {},
   "source": [
    "### Create Constellations Facility Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Constellations Nuclear Facility Code and Name\n",
    "constellation_nuclear_facility = [{\"code\":\"CAL\", \"name\":\"Calvert Cliffs\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"GIN\", \"name\":\"Ginna\", \"alt\":\"GNA\"},\n",
    "                                  {\"code\":\"DRE\", \"name\":\"Dresden\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"QDC\", \"name\":\"Quad Cities\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"JAF\", \"name\":\"Fitzpatrick\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"CPS\", \"name\":\"Clinton\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"NMP\", \"name\":\"Nine Mile Point\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"LAS\", \"name\":\"LaSalle\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"LIM\", \"name\":\"Limerick\", \"alt\":\"LGS\"},\n",
    "                                  {\"code\":\"PEA\", \"name\":\"Peach Bottom\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"TMI\", \"name\":\"Three Mile Island\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"BYR\", \"name\":\"Byron\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"BRW\", \"name\":\"Braidwood\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"ZIN\", \"name\":\"Zion\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"OYS\", \"name\":\"Oyster Creek\", \"alt\":\"\"},\n",
    "                                  {\"code\":\"NCS\", \"name\":\"Nuclear Corporate\", \"alt\":\"\"}]\n",
    "\n",
    "# Create a mapping dictionary from the list of dictionaries\n",
    "mapping_dict = {item['name']: item['code'] for item in constellation_nuclear_facility}\n",
    "\n",
    "# Accessing the dictionary\n",
    "for item in constellation_nuclear_facility:\n",
    "    print(f\"Code: {item['code']}, Name: {item['name']}, AlternateCode: {item['alt']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a3f17",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the dictionary contains the target value\n",
    "def search_dict(text, nuclear_facility_list):\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, nuclear_facility_list)) + r')\\b'\n",
    "    return bool(re.search(pattern, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb673ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign codes based on patterns\n",
    "def assign_code(text):\n",
    "    for facility, code in mapping_dict.items():\n",
    "        if facility in text:\n",
    "            return code\n",
    "    return 'Unknown' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641eeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d91ab",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba41b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "df_cleaned = df.dropna(subset=['FACILITYNAME'])\n",
    "df_cleaned = df_cleaned[~df_cleaned['EVENTDATE'].str.contains('None', case=False, na=False)]\n",
    "df_cleaned = df_cleaned[~df_cleaned['EVENTDATE'].str.contains('\\n', case=False, na=False)]\n",
    "df_cleaned = df_cleaned[~df_cleaned['EVENTDATE'].str.contains(r'\\.', case=False, na=False)]\n",
    "\n",
    "df_cleaned['EVENT_DATE'] = pd.to_datetime(df_cleaned['EVENTDATE'], format='mixed').dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "facility_names = [item[\"name\"] for item in constellation_nuclear_facility]\n",
    "df_cleaned['CONTAINS_FACILITY'] = df_cleaned['FACILITYNAME'].apply(lambda x: search_dict(x, facility_names))\n",
    "df_cleaned['FACILITY_CODE'] = df_cleaned['FACILITYNAME'].apply(assign_code)\n",
    "df_constellation_lers = df_cleaned[df_cleaned['FACILITY_CODE']!='Unknown']\n",
    "df_constellation_lers = df_constellation_lers[~df_constellation_lers[['EVENT_DATE', 'FACILITY_CODE']].duplicated()]\n",
    "print(len(df_constellation_lers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facility to LER distribution\n",
    "sns.histplot(data=df_constellation_lers, x=\"FACILITY_CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for fetching classifier dataset from AS9\n",
    "def fetch_classifier_dataset(df):\n",
    "    conn_str = (\n",
    "        f\"DRIVER={{Oracle in OraClient19Home1}};\"\n",
    "        f\"DBQ=AS9NUCRP;\"\n",
    "        f\"UID=;\"\n",
    "        f\"PWD=;\"\n",
    "    )\n",
    " \n",
    "    eventDates = tuple(df['EVENT_DATE'].unique())\n",
    "    facilities = tuple(df['FACILITY_CODE'].unique())\n",
    "\n",
    "    query = f\"\"\"\n",
    "                WITH\n",
    "                -- POSITIVE CLASS CTE \n",
    "                LER_POSITIVE_CTE AS (\n",
    " \n",
    "                    SELECT \n",
    "                        DISTINCT (CASE WHEN T1.AR_NUMBER = '04501492' THEN '04501564'\n",
    "                                    ELSE T1.AR_NUMBER\n",
    "                                END) AS AR_NUMBER,\n",
    "                        T1.AR_ORIG_FACILITY,\n",
    "                        T1.EVENT_DATE,\n",
    "                        T1.AR_PRIORITY,\n",
    "                        T1.AR_SEVERITY\n",
    "                    FROM TIDARMST T1\n",
    "                    JOIN TIDASMST T2\n",
    "                        ON T1.AR_NUMBER = T2.AR_NUMBER\n",
    "                    WHERE \n",
    "                    T2.ASSIGN_TYPE = 'LER'\n",
    "                    AND TRIM(T1.AR_ORIG_FACILITY) IS NOT NULL\n",
    "                    AND TRIM(T1.EVENT_DATE) IS NOT NULL\n",
    "                    AND T1.AR_TYPE = 'CR'\n",
    "                    AND T1.EVENT_DATE IN {eventDates}\n",
    "                    AND T1.AR_ORIG_FACILITY IN {facilities}\n",
    "                ),\n",
    "            \n",
    "                -- NEGATIVE CLASS CTE\n",
    "                LER_NEGATIVE_CTE AS (\n",
    "                    SELECT * \n",
    "                    FROM (   \n",
    "                        SELECT \n",
    "                            DISTINCT T1.AR_NUMBER,\n",
    "                            T1.AR_ORIG_FACILITY,\n",
    "                            T1.EVENT_DATE,\n",
    "                            T1.AR_PRIORITY,\n",
    "                            T1.AR_SEVERITY\n",
    "                        FROM TIDARMST T1\n",
    "                        WHERE T1.AR_NUMBER NOT IN (SELECT AR_NUMBER FROM LER_POSITIVE_CTE)\n",
    "                            AND TRIM(T1.AR_ORIG_FACILITY) IS NOT NULL\n",
    "                            AND TRIM(T1.EVENT_DATE) IS NOT NULL\n",
    "                            AND T1.AR_TYPE = 'CR'\n",
    "                            AND T1.EVENT_DATE >= (SELECT MIN(EVENT_DATE) FROM LER_POSITIVE_CTE)\n",
    "                            AND T1.AR_SUBJECT NOT LIKE '%AUTO-CANCELED%'\n",
    "                            AND TRIM(T1.AR_SEVERITY) IS NOT NULL\n",
    "                            AND TRIM(T1.AR_PRIORITY) IS NOT NULL\n",
    "                        ORDER BY DBMS_RANDOM.VALUE\n",
    "                        )\n",
    "                    WHERE ROWNUM <= 565\n",
    "                )\n",
    "\n",
    "                -- POSITIVE CLASS\n",
    "                SELECT T1.AR_NUMBER,\n",
    "                        T1.AR_ORIG_FACILITY,\n",
    "                        T1.EVENT_DATE,\n",
    "                        T1.AR_PRIORITY,\n",
    "                        T1.AR_SEVERITY,\n",
    "                        RTRIM(\n",
    "                            REPLACE(\n",
    "                                REPLACE(\n",
    "                                    XMLAGG(\n",
    "                                        XMLELEMENT(\"x\", REGEXP_REPLACE(T2.DESCRIPTION_NOTES, '[^[:print:]]', '') || ' ')\n",
    "                                        ORDER BY T2.GEN_ARG\n",
    "                                    ).GetClobVal(),\n",
    "                                    '<x>', ''),\n",
    "                                '</x>', '')\n",
    "                            , ' ') AS CONTENT,\n",
    "                        1 AS LER_LABEL\n",
    "                FROM LER_POSITIVE_CTE T1\n",
    "                JOIN TIDARCOM T2\n",
    "                    ON T1.AR_NUMBER = T2.AR_NUMBER\n",
    "                WHERE T2.AR_COMMENT_TYPE = 'D'\n",
    "                GROUP BY T1.AR_NUMBER, T1.AR_ORIG_FACILITY, T1.EVENT_DATE, T1.AR_PRIORITY, T1.AR_SEVERITY\n",
    "\n",
    "                UNION ALL\n",
    "                \n",
    "                -- NEGATIVE CLASS\n",
    "                SELECT T1.AR_NUMBER,\n",
    "                        T1.AR_ORIG_FACILITY,\n",
    "                        T1.EVENT_DATE,\n",
    "                        T1.AR_PRIORITY,\n",
    "                        T1.AR_SEVERITY,\n",
    "                        RTRIM(\n",
    "                            REPLACE(\n",
    "                                REPLACE(\n",
    "                                    XMLAGG(\n",
    "                                        XMLELEMENT(\"x\", REGEXP_REPLACE(T2.DESCRIPTION_NOTES, '[^[:print:]]', '') || ' ')\n",
    "                                        ORDER BY T2.GEN_ARG\n",
    "                                    ).GetClobVal(),\n",
    "                                    '<x>', ''),\n",
    "                                '</x>', '')\n",
    "                            , ' ') AS CONTENT,\n",
    "                        0 AS LER_LABEL\n",
    "                FROM LER_NEGATIVE_CTE T1\n",
    "                JOIN TIDARCOM T2\n",
    "                    ON T1.AR_NUMBER = T2.AR_NUMBER\n",
    "                WHERE T2.AR_COMMENT_TYPE = 'D'\n",
    "                GROUP BY T1.AR_NUMBER, T1.AR_ORIG_FACILITY, T1.EVENT_DATE, T1.AR_PRIORITY, T1.AR_SEVERITY\n",
    "    \"\"\"\n",
    " \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    df = df[df['CONTENT'].str.strip().astype(bool)]\n",
    "\n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "df = fetch_classifier_dataset(df_constellation_lers)\n",
    "print(f\"Fetched {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20cb8f3",
   "metadata": {},
   "source": [
    "### Save LER to IR mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"AR_NUMBER\", \"LERNUMBER\", \"EVENT_DATE\", \"AR_ORIG_FACILITY\", \"LER_LABEL\", \"FILENAME\"]\n",
    "\n",
    "df_lers = pd.merge(df[df[\"LER_LABEL\"]==1], df_constellation_lers, how='left', \n",
    "                            left_on=['EVENT_DATE', 'AR_ORIG_FACILITY'], right_on=['EVENT_DATE', 'FACILITY_CODE'])\n",
    "df_lers = df_lers[columns].to_csv(ler_ir_map_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88c4cd",
   "metadata": {},
   "source": [
    "### Extract document sections and create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44fd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pattern to match and extract\n",
    "pattern1 = r\"Condition Description:\\s*(.*?)(?=\\s*(Immediate actions taken|Recommended Actions):|$)\"\n",
    "pattern2 = r\"Immediate actions taken:\\s*(.*?)(?=\\s*(Recommended Actions|Initial Screening Questions):|$)\"\n",
    "\n",
    "# Clean dataset\n",
    "df['COND_DESC'] = df['CONTENT'].apply(lambda text: Common.preprocess_text(text, pattern1, clean_text=False))\n",
    "df['IMME_ACTN'] = df['CONTENT'].apply(lambda text: Common.preprocess_text(text, pattern2, clean_text=False))\n",
    "\n",
    "\n",
    "# Generate embeddings using default vectorization (ada-002)\n",
    "X_COND_DESC = azure_openai.generate_embeddings(entries=df['COND_DESC'],\n",
    "                                            embedding_model_id=embedding_model)\n",
    "if len(X_COND_DESC) == 0:\n",
    "    print('\\t\\tError generating default embeddings')\n",
    "    sys.exit(\"Errors!\")\n",
    "\n",
    "X_IMME_ACTN = azure_openai.generate_embeddings(entries=df['IMME_ACTN'],\n",
    "                                            embedding_model_id=embedding_model)\n",
    "if len(X_IMME_ACTN) == 0:\n",
    "    print('\\t\\tError generating default embeddings')\n",
    "    sys.exit(\"Errors!\")\n",
    "\n",
    "df['VEC_DEF_1'] = X_COND_DESC\n",
    "df['VEC_DEF_2'] = X_IMME_ACTN\n",
    "\n",
    "df = df[df['VEC_DEF_1'] != -99999.99999]\n",
    "df = df[df['VEC_DEF_2'] != -99999.99999]\n",
    "\n",
    "X_full = pd.concat([df['VEC_DEF_1'].apply(pd.Series), df['VEC_DEF_2'].apply(pd.Series)], axis=1)\n",
    "X_full['FACILITY'] = df['AR_ORIG_FACILITY'].astype('category')\n",
    "y_full = df['LER_LABEL'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f554000",
   "metadata": {},
   "source": [
    "### Fixed Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fefe54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492f349",
   "metadata": {},
   "source": [
    "### Separate Categorical and Non-Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f06786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noncat = X_train.iloc[:,:-1]\n",
    "X_test_noncat = X_test.iloc[:,:-1]\n",
    "X_train_cat = X_train[['FACILITY']]\n",
    "X_test_cat = X_test[['FACILITY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7b37c",
   "metadata": {},
   "source": [
    "### Scale and Reduce Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9abbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features before PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_noncat)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_noncat)\n",
    "X_test_scaled = scaler.transform(X_test_noncat)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Find the number of components that explain at least 95% variance\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Number of components explaining 95% variance: {n_components}\")\n",
    "\n",
    "# Apply PCA with the selected number of components\n",
    "pca_95 = PCA(n_components=n_components)\n",
    "pca_95.fit(X_train_scaled)\n",
    "\n",
    "X_train_pca = pd.DataFrame(pca_95.transform(X_train_scaled))\n",
    "X_test_pca = pd.DataFrame(pca_95.transform(X_test_scaled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745481c4",
   "metadata": {},
   "source": [
    "### One-Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the categorical features\n",
    "cat_attribs = ['FACILITY']\n",
    "\n",
    "transformer = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), cat_attribs)], remainder='passthrough')\n",
    "\n",
    "encoder = transformer.fit(X_train_cat)\n",
    "X_train_encode =  pd.DataFrame(encoder.transform(X_train_cat).toarray())\n",
    "X_test_encode = pd.DataFrame(encoder.transform(X_test_cat).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315597c9",
   "metadata": {},
   "source": [
    "### Combine both above dataset to create final feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201585dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both datasets\n",
    "X_train_final = pd.concat([X_train_pca.reset_index(), X_train_encode.reset_index()], axis=1, ignore_index=True)\n",
    "X_test_final = pd.concat([X_test_pca.reset_index(), X_test_encode.reset_index()], axis=1, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "X_train_final.columns = [f'col_{i}' for i in range(X_train_final.shape[1])]\n",
    "X_test_final.columns = [f'col_{i}' for i in range(X_test_final.shape[1])]\n",
    "\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d31b2",
   "metadata": {},
   "source": [
    "### Train model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d336bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_model = XGBClassifier(n_estimators=10, max_depth=4, learning_rate=0.05)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_test_proba = xgb_model.predict_proba(X_test_final)[:, 1]\n",
    "y_train_proba = xgb_model.predict_proba(X_train_final)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall with threshold to analyse visually\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_test_proba)\n",
    "auc_score = auc(recall, precision)\n",
    "\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.title(\"Precision-Recall vs Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f'Precision-Recall Curve (AUC = {auc_score:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best threshold\n",
    "f1_scores = 2 * recall * precision / (recall + precision)\n",
    "best_thresh = thresholds[np.argmax(f1_scores)]\n",
    "best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db47fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = (y_test_proba > best_thresh).astype(int)\n",
    "\n",
    "out_df = pd.DataFrame({\"Pred\": y_test_pred, \"True\": y_test, \"Prob\":y_test_proba})\n",
    "out_df = out_df.sort_values(by='Prob')\n",
    "out_df.to_csv(test_pred_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10881414",
   "metadata": {},
   "source": [
    "### Run full data thru the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_noncat = X_full.iloc[:,:-1]\n",
    "X_full_cat = X_full[['FACILITY']]\n",
    "\n",
    "X_full_scaled = scaler.transform(X_full_noncat)\n",
    "X_full_pca = pd.DataFrame(pca_95.transform(X_full_scaled))\n",
    "X_full_encode =  pd.DataFrame(encoder.transform(X_full_cat).toarray())\n",
    "X_full_final = pd.concat([X_full_pca.reset_index(), X_full_encode.reset_index()], axis=1, ignore_index=True)\n",
    "\n",
    "X_full_final.columns = [f'col_{i}' for i in range(X_full_final.shape[1])]\n",
    "\n",
    "y_pred_proba_full = xgb_model.predict_proba(X_full_final)[:, 1]\n",
    "y_pred_full = (y_pred_proba_full > best_thresh).astype(int)\n",
    "\n",
    "\n",
    "print(\"--------------- TRAIN SCORES ------------------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_full, y_pred_full):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_full, y_pred_full)}\")\n",
    "print(f\"Recall: {recall_score(y_full, y_pred_full)}\")\n",
    "print(f\"F1 Score: {f1_score(y_full, y_pred_full):.2f}\")\n",
    "# Confusion Matrix\n",
    "cfm = confusion_matrix(y_full, y_pred_full).flatten()\n",
    "print(f\"Confusion Matrix: TP -> {cfm[3]}, FN -> {cfm[2]}, FP -> {cfm[1]}, TN -> {cfm[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7316d",
   "metadata": {},
   "source": [
    "### Save full dataset output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\"Pred\": y_pred_full, \n",
    "                       \"True\": y_full, \n",
    "                       \"Prob\": y_pred_proba_full})\n",
    "df_complete = pd.concat([df, out_df], axis=1)\n",
    "df_complete[[\"AR_NUMBER\", \"Pred\",\"True\",\"Prob\"]].sort_values(by='Prob').to_csv(full_pred_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cda7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram\n",
    "sns.histplot(data=out_df, x=\"Prob\", hue=\"Pred\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ecff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_full = squareform(pdist(df_complete[\"VEC_DEF_1\"].apply(pd.Series), metric='cosine'))\n",
    "distance_df_full = pd.DataFrame(distance_matrix_full, index=df_complete.index, columns=df_complete.index)\n",
    "# distance_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b62783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(distance_df_full, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Row-wise Distance Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76703e",
   "metadata": {},
   "source": [
    "### Filter records for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389af7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df_complete[(df_complete[\"Prob\"]>=(best_thresh - 0.05)) & \n",
    "                          (df_complete[\"Prob\"]<=(best_thresh + 0.05)) & \n",
    "                          (df_complete[\"Pred\"]!=df_complete[\"True\"])]\n",
    "len(df_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25565457",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = squareform(pdist(df_analysis[\"VEC_DEF_1\"].apply(pd.Series), metric='cosine'))\n",
    "distance_df = pd.DataFrame(distance_matrix, index=df_analysis.index, columns=df_analysis.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismatched records\n",
    "sns.histplot(data=df_analysis, x=\"Prob\", hue=\"True\", kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f932d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(distance_df, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Row-wise Distance Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis[(df_analysis[\"True\"] == 1) & (df_analysis[\"Pred\"] == 0)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis[(df_analysis[\"True\"] == 0) & (df_analysis[\"Pred\"] == 1)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01010111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LER\n",
    "wrapped_column= df_analysis[df_analysis[\"AR_NUMBER\"]=='01299156']['COND_DESC'].str.wrap(width=40)\n",
    "for value in wrapped_column:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON LER\n",
    "wrapped_column= df_analysis[df_analysis[\"AR_NUMBER\"]=='02449287']['COND_DESC'].str.wrap(width=40)\n",
    "for value in wrapped_column:\n",
    "    print(value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
