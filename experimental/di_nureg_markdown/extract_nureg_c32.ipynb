{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290274b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest, DocumentContentFormat\n",
    "from azure.identity import ClientSecretCredential\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading variables from .env into the environment\n",
    "load_dotenv()\n",
    "# Intializing Azure Credential\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "# Analyze the document\n",
    "nureg_pdf_url=\"https://czvgnalcs00dsta001.blob.core.usgovcloudapi.net/non-eci/nureg/ML13032A220.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_layout(nureg_pdf_url):\n",
    "    '''function to extract the pdf data using document intelligence in markdown format'''\n",
    "    # Initialize the Document Intelligence client\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT, credential=AzureKeyCredential(AZURE_DOCUMENT_INTELLIGENCE_KEY )\n",
    "    )\n",
    "    \n",
    "    # Start the analysis process\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        model_id=\"prebuilt-layout\",\n",
    "        body=AnalyzeDocumentRequest(url_source=nureg_pdf_url),\n",
    "        output_content_format=DocumentContentFormat.MARKDOWN\n",
    "    )\n",
    "    \n",
    "    # Retrieve the result\n",
    "    AnalyzeResult = poller.result()\n",
    "    return AnalyzeResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7111b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_number(section_text):\n",
    "    ''' Extracting section page numbers from where the section starts'''\n",
    "    # Check if the comment <!-- PageNumber=... --> exists\n",
    "    comment_exists = re.search(r'<!--\\s*PageNumber\\s*=\\s*\"?\\d+\"?\\s*-->', section_text, re.IGNORECASE)\n",
    "\n",
    "    # If the comment exists, get the page_no and return page_no - 1\n",
    "    if comment_exists:\n",
    "        page_no_match = re.search(r'page_no:\\s*(\\d+)', section_text, re.IGNORECASE)\n",
    "        if page_no_match:\n",
    "            return int(page_no_match.group(1)) - 1\n",
    "    else:\n",
    "        # If no comment, just return the page_no as-is\n",
    "        page_no_match = re.search(r'page_no:\\s*(\\d+)', section_text, re.IGNORECASE)\n",
    "        if page_no_match:\n",
    "            return int(page_no_match.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_sub_section(section_text: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Extracting 50.72 & 50.73 section labels from table\n",
    "    \"\"\"\n",
    "    # searching for table\n",
    "    table_match = re.search(r'<table>.*?</table>', section_text, re.DOTALL)\n",
    "    # regex to match 50.72 & 50.73 in table\n",
    "    matches = re.findall(r'§\\s*50\\.72(?:\\([^)]+\\))*|§\\s*50\\.73(?:\\([^)]+\\))*', table_match.group(0))\n",
    "    \n",
    "    # Separate into two lists\n",
    "    list_50_72 = [match for match in matches if match.startswith('§ 50.72')]\n",
    "    list_50_73 = [match for match in matches if match.startswith('§ 50.73')]\n",
    "    # Edge case: if subsection is not captured\n",
    "    if len(list_50_72)==0 | len(list_50_73)==0:\n",
    "      list_50_72, list_50_73 = _extract_sub_section_edgecase(section_text)\n",
    "    return list_50_72, list_50_73\n",
    "\n",
    "def _extract_sub_section_edgecase(section_text):\n",
    "    ''' Function to handle edgecase in extracting sub section '''\n",
    "    # Step 1: Split into lines and collect until a 'Discussion' header\n",
    "    lines = section_text.splitlines()\n",
    "    collected = []\n",
    "    for line in lines:\n",
    "        # Stop when we hit a heading like \"### Discussion\" (any level)\n",
    "        if re.match(r'#{1,6}\\s+Discussion([ \\t]*[a-zA-Z0-9])?', line.strip()):\n",
    "            break\n",
    "        collected.append(line)\n",
    "    examples_text = \"\\n\".join(collected).strip()\n",
    "    # Step 2: Regex to extract § 50.72... and § 50.73... with groups\n",
    "    pattern = r'§\\s*50\\.72(?:\\([^)]+\\))*|§\\s*50\\.73(?:\\([^)]+\\))*'\n",
    "    matches = re.findall(pattern, examples_text, re.DOTALL)\n",
    "    # Separate into two lists\n",
    "    list_50_72 = [match for match in matches if match.startswith('§ 50.72')]\n",
    "    list_50_73 = [match for match in matches if match.startswith('§ 50.73')]\n",
    "    return list_50_72, list_50_73\n",
    "\n",
    "    \n",
    "def clean_text(raw_text):\n",
    "    ''' Cleaning text'''\n",
    "    \n",
    "    # Clean unwanted formatting\n",
    "    text_clean = re.sub(r'<!--.*?-->', '', raw_text)        # remove HTML comments\n",
    "    text_clean = re.sub(r'\\n+', ' ', text_clean)            # collapse line breaks\n",
    "    text_clean = re.sub(r'\\s{2,}', ' ', text_clean)         # collapse extra spaces\n",
    "    text_clean = re.sub(r'\\bPageNumber=\"?[\\dixv]+\"?', '', text_clean, flags=re.IGNORECASE)\n",
    "    text_clean = re.sub(r'^\\s*\\d+\\s*$', '', text_clean, flags=re.MULTILINE)  # orphaned page numbers\n",
    "    text_clean = re.sub(r'^#{1,10}\\s+', '', text_clean, flags=re.MULTILINE)\n",
    "\n",
    "    return text_clean\n",
    "\n",
    "def extract_description(section_text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts description after one or more consecutive <table> blocks\n",
    "    that are optionally split by <!-- PageBreak -->.\n",
    "    \"\"\"\n",
    "    pos = 0\n",
    "    while True:\n",
    "        # 1. Find </table>\n",
    "        table_end = re.search(r'</table>', section_text[pos:], re.IGNORECASE)\n",
    "        if not table_end:\n",
    "            return None\n",
    "\n",
    "        # Update absolute position\n",
    "        pos += table_end.end()\n",
    "        \n",
    "        # 2. Look ahead for <!-- PageBreak --> followed by <table>\n",
    "        lookahead = section_text[pos:]\n",
    "        if '<table>' not in lookahead[:70]:\n",
    "            break\n",
    "\n",
    "        # If found, find the next </table> again\n",
    "        pagebreak_table_end = re.search(r'</table>', lookahead, re.IGNORECASE)\n",
    "        if not pagebreak_table_end:\n",
    "            break  # malformed, but safe exit\n",
    "\n",
    "        # Advance absolute position to end of next </table>\n",
    "        pos += pagebreak_table_end.end()\n",
    "\n",
    "    # 3. Now extract description from pos until next header\n",
    "    remaining = section_text[pos:]\n",
    "    desc_match = re.search(\n",
    "        r\"(.*?)(?=\\n\\s*#+|\\n-{3,}|\\n\\s*Table|\\n\\s*Discussion|\\n\\s*Examples|\\Z)\",\n",
    "        remaining,\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    if not desc_match:\n",
    "        return None\n",
    "\n",
    "    # 4. Cleanup\n",
    "    description = desc_match.group(1)\n",
    "    description_clean = clean_text(description) \n",
    "    return description_clean.strip() if description_clean.strip() else None\n",
    "\n",
    "\n",
    "def extract_discussion(section_text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts the text under the 'Discussion' header until the next section or 'Examples'.\n",
    "    \"\"\"\n",
    "    start_match = re.search(r'#{1,6}\\s+Discussion([ \\t]*[a-zA-Z0-9])?', section_text)\n",
    "    if not start_match:\n",
    "        return None\n",
    "\n",
    "    start_pos = start_match.end()\n",
    "    rest = section_text[start_pos:]\n",
    "\n",
    "    # Split text into lines and iterate until we hit ## 3.2.x\n",
    "    lines = rest.splitlines()\n",
    "    collected = []\n",
    "    for line in lines:\n",
    "        if re.match(r'#{1,6}\\s+Examples?\\b', line.strip()):\n",
    "            break\n",
    "        collected.append(line)\n",
    "\n",
    "    discussion = \"\\n\".join(collected).strip()\n",
    "    discussion_clean = clean_text(discussion)\n",
    "\n",
    "    return discussion_clean\n",
    "\n",
    "\n",
    "def extract_examples(section_text: str) -> Optional[List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Extracts the text under the 'Examples' header until the next section header (like 3.2.x)\n",
    "    and returns a list of dictionaries with Title and Description.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_match = re.search(r'#{1,6}\\s+Examples?', section_text)\n",
    "    if not start_match:\n",
    "        return None\n",
    "\n",
    "    start_pos = start_match.end()\n",
    "    rest = section_text[start_pos:]\n",
    "\n",
    "    # Split text into lines and iterate until we hit ## 3.2.x\n",
    "    lines = rest.splitlines()\n",
    "    collected = []\n",
    "    for line in lines:\n",
    "        if re.match(r'#{1,6}\\s+3\\.2\\.\\d+', line.strip()):\n",
    "            break\n",
    "        collected.append(line)\n",
    "\n",
    "    examples_text = \"\\n\".join(collected).strip()\n",
    "\n",
    "    # Flexible heading level pattern for examples\n",
    "    pattern = r\"#{1,6}\\s+\\(\\d+\\)\\s+([^\\n]+)\\n(.*?)(?=(?:#{1,6}\\s+\\(\\d+\\)|\\Z))\"\n",
    "    matches = re.findall(pattern, examples_text, re.DOTALL)\n",
    "\n",
    "    # Format into list of dicts\n",
    "    # examples = [{\"Title\": title.strip(), \"Description\": text.strip()} for title, text in matches]\n",
    "    if matches:\n",
    "        examples = [{\"Title\": title.strip(), \"Description\": text.strip()} for title, text in matches]\n",
    "    else:\n",
    "        # examples = [{\"Title\": None, \"Description\": examples_text}]\n",
    "        parts = examples_text.split(\"\\n\\n\", 1)\n",
    "        title = parts[0].strip() if parts else None\n",
    "        description = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        examples = [{\"Title\": title, \"Description\": description}]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data in markdown format using DocIntelligence\n",
    "markdown_result = analyze_layout(nureg_pdf_url)\n",
    "markdown_text = markdown_result.content \n",
    "\n",
    "# Numbering pages\n",
    "# Replace PageBreak with numbered breaks\n",
    "markdown_text = markdown_result.content \n",
    "pages = markdown_text.split(\"<!-- PageBreak -->\")\n",
    "numbered_markdown = \"\\n\\n\".join(\n",
    "    f\" ----- page_no: {i+1}\\n\\n{page.strip()}\" for i, page in enumerate(pages)\n",
    ")\n",
    "\n",
    "# storing as txt file\n",
    "# with open('markdown_with_page_no.txt', 'w', encoding='utf-8') as f:\n",
    "#     f.write(numbered_markdown)\n",
    "\n",
    "# Split text by subsection markers (e.g., \"3.2.1 Some Title\")\n",
    "subsections = re.split(r'(?:^|\\n)###*\\s*(3\\.2\\.\\d+)\\s+(.+)', numbered_markdown)\n",
    "\n",
    "# Initialize structured output\n",
    "structured_data = []\n",
    "\n",
    "# Iterate over the split text\n",
    "for i in range(1, len(subsections), 3):\n",
    "    section_number = subsections[i].strip()\n",
    "    section_title  = subsections[i + 1].strip()\n",
    "    section_text   = subsections[i + 2]\n",
    "\n",
    "    section_page_no = extract_page_number(section_text)\n",
    "\n",
    "    # Extract subsections from table\n",
    "    subsection_5072, subsection_5073 = extract_sub_section(section_text)\n",
    "\n",
    "\n",
    "    # Description: first paragraph after table that is not a header\n",
    "    description = extract_description(section_text)\n",
    "\n",
    "    # Discussion\n",
    "    discussion = extract_discussion(section_text)\n",
    "\n",
    "    # Examples\n",
    "    examples = extract_examples(section_text)\n",
    "\n",
    "    # Final structure\n",
    "    data = {\n",
    "        'Section Number': section_number,\n",
    "        'Section Title': section_title,\n",
    "        'Section Page Number': section_page_no,\n",
    "        'sub_section_5072': subsection_5072,\n",
    "        'sub_section_5073': subsection_5073,\n",
    "        'Description': description,\n",
    "        'Discussion': discussion,\n",
    "        'Examples': examples\n",
    "        \n",
    "    }\n",
    "\n",
    "    structured_data.append(data)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68787ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving output in a json file\n",
    "with open('structure_output.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(structured_data, json_file, ensure_ascii=False, indent=4) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
